#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlitã‚’ä½¿ã£ãŸè­°äº‹éŒ²RAGã‚·ã‚¹ãƒ†ãƒ ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import streamlit as st
import os
from datetime import datetime
from typing import List, Dict, Any
import chromadb
from chromadb.config import Settings
from pathlib import Path
import openai
from dotenv import load_dotenv
import numpy as np

# SentenceTransformerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

# OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
try:
    openai_version = openai.__version__
except:
    openai_version = "ä¸æ˜"

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")



class MeetingRAGSystem:
    """è­°äº‹éŒ²RAGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = "./chroma_db"):
        """
        åˆæœŸåŒ–
        
        Args:
            db_path: ChromaDBã®ä¿å­˜ãƒ‘ã‚¹
        """
        self.db_path = db_path
        self.collection = None # å…ˆã«åˆæœŸåŒ–
        self.embedding_model = None # å…ˆã«åˆæœŸåŒ–

        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            try:
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                st.sidebar.info("âœ… åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.sidebar.error(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        else:
            st.sidebar.error("sentence-transformersãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚")
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        try:
            self.client = chromadb.PersistentClient(
                path=db_path,
                settings=Settings(anonymized_telemetry=False)
            )
            
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
            self.collection_name = "meeting_minutes"
            
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å–å¾—
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                st.success(f"ChromaDBã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{self.collection_name}' ã«æ¥ç¶šã—ã¾ã—ãŸ")
            except:
                st.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{self.collection_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«è­°äº‹éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
                self.collection = None
                
        except Exception as e:
            st.error(f"ChromaDBã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            self.collection = None
    
    def search_documents(self, query: str, n_results: int = 5, similarity_threshold: float = 0.3) -> List[Dict[str, Any]]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            n_results: å–å¾—ã™ã‚‹çµæœæ•°
            
        Returns:
            æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        if not self.collection:
            return []
        if self.embedding_model is None:
            st.error("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€æ¤œç´¢ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
            return []

        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_embedding = self.embedding_model.encode(query)
            # å…¨ä»¶å–å¾—
            all_data = self.collection.get(include=["embeddings", "documents", "metadatas"])
            results = []
            for doc, meta, emb in zip(all_data["documents"], all_data["metadatas"], all_data["embeddings"]):
                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
                if emb is not None:
                    sim = np.dot(query_embedding, emb) / (np.linalg.norm(query_embedding) * np.linalg.norm(emb))
                else:
                    sim = 0.0
                if sim >= similarity_threshold:
                    results.append({
                        "content": doc,
                        "metadata": meta,
                        "similarity": sim
                    })
            # é¡ä¼¼åº¦ã§é™é †ã‚½ãƒ¼ãƒˆ
            results.sort(key=lambda x: x["similarity"], reverse=True)
            # ä¸Šä½nä»¶ã ã‘è¿”ã™
            return results[:n_results]
        except Exception as e:
            st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []
    
    def get_collection_info(self) -> Dict[str, Any]:
        """
        ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®æƒ…å ±ã‚’å–å¾—
        
        Returns:
            ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
        """
        if not self.collection:
            return {"total_count": 0, "type_counts": {}, "file_counts": {}}
        
        try:
            count = self.collection.count()
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’å–å¾—
            all_data = self.collection.get(include=["embeddings", "documents", "metadatas"])  # æ˜ç¤ºçš„ã«embeddingsã‚’å«ã‚ã‚‹
            type_counts = {}
            file_counts = {}
            
            for metadata in all_data["metadatas"]:
                if metadata:
                    # ã‚¿ã‚¤ãƒ—åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
                    chunk_type = metadata.get("chunk_type", "unknown")
                    type_counts[chunk_type] = type_counts.get(chunk_type, 0) + 1
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
                    file_name = metadata.get("file_name", "unknown")
                    file_counts[file_name] = file_counts.get(file_name, 0) + 1
            
            return {
                "total_count": count,
                "type_counts": type_counts,
                "file_counts": file_counts
            }
            
        except Exception as e:
            st.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"total_count": 0, "type_counts": {}, "file_counts": {}}
    
    def generate_ai_response(self, query: str, context_docs: List[Dict[str, Any]]) -> str:
        """
        AIã‚’ä½¿ã£ã¦å›ç­”ã‚’ç”Ÿæˆ
        
        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            context_docs: é–¢é€£æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            AIã®å›ç­”
        """
        if not OPENAI_API_KEY:
            return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        
        try:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆã‚ˆã‚Šæ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ï¼‰
            context_parts = []
            total_tokens_estimate = 0
            
            for i, doc in enumerate(context_docs):
                metadata = doc['metadata']
                
                # æ–‡æ›¸ã®é‡è¦åº¦ã‚’è¨ˆç®—ï¼ˆé¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
                similarity = doc.get('similarity', 0.0)
                
                # é¡ä¼¼åº¦ãŒé«˜ã„æ–‡æ›¸ã¯ã‚ˆã‚Šè©³ç´°ã«è¡¨ç¤º
                if similarity >= 0.7:  # é«˜é¡ä¼¼åº¦ï¼ˆ70%ä»¥ä¸Šï¼‰
                    context_parts.append(f"""ã€æ–‡æ›¸{i+1} - é«˜é–¢é€£ã€‘
ã‚¿ã‚¤ãƒ—: {metadata.get('type', 'N/A')}
ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('title', 'N/A')}
ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('subtitle', 'N/A')}
é–¢é€£åº¦: {similarity:.1%}
å†…å®¹: {doc['content']}
---""")
                elif similarity >= 0.5:  # ä¸­é¡ä¼¼åº¦ï¼ˆ50-70%ï¼‰
                    context_parts.append(f"""ã€æ–‡æ›¸{i+1} - ä¸­é–¢é€£ã€‘
ã‚¿ã‚¤ãƒ—: {metadata.get('type', 'N/A')}
ã‚¿ã‚¤ãƒˆãƒ«: {metadata.get('title', 'N/A')}
é–¢é€£åº¦: {similarity:.1%}
å†…å®¹: {doc['content'][:500]}{'...' if len(doc['content']) > 500 else ''}
---""")
                else:  # ä½é¡ä¼¼åº¦ï¼ˆ30-50%ï¼‰
                    context_parts.append(f"""ã€æ–‡æ›¸{i+1} - ä½é–¢é€£ã€‘
ã‚¿ã‚¤ãƒ—: {metadata.get('type', 'N/A')}
é–¢é€£åº¦: {similarity:.1%}
å†…å®¹: {doc['content'][:300]}{'...' if len(doc['content']) > 300 else ''}
---""")
                
                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—ï¼ˆGPT-4ã¯1ãƒˆãƒ¼ã‚¯ãƒ³â‰ˆ4æ–‡å­—ï¼‰
                total_tokens_estimate += len(str(context_parts[-1])) // 4
                
                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¤šã™ãã‚‹å ´åˆã¯è­¦å‘Š
                if total_tokens_estimate > 8000:  # GPT-4ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã‚’è€ƒæ…®
                    st.warning(f"âš ï¸ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ããªã‚Šã™ãã¦ã„ã¾ã™ï¼ˆæ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {total_tokens_estimate}ï¼‰ã€‚æœ€åˆã®{i+1}ä»¶ã®æ–‡æ›¸ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    break
            
            context_text = "\n\n".join(context_parts)

            # æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            system_prompt = """ã‚ãªãŸã¯è­°äº‹éŒ²ã‚„æ–­ç‰‡çš„ãªçŸ¥è­˜ã‚’ã‚‚ã¨ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦
çµ±åˆçš„ã‹ã¤è€ƒå¯Ÿã‚’å«ã‚ãŸå›ç­”ã‚’è¡Œã†å°‚é–€å®¶ã§ã™ã€‚

# å›ç­”ãƒ«ãƒ¼ãƒ«
1. **è¤‡æ•°ã®æ–‡æ›¸ã‚„æ–­ç‰‡çš„ãªæƒ…å ±ã‚’ç·åˆçš„ã«æ•´ç†ã—ã€å¿…è¦ã«å¿œã˜ã¦æ¨è«–ã‚„è€ƒå¯Ÿã‚‚åŠ ãˆã¦ãã ã•ã„**
2. **æ ¹æ‹ ã¨ãªã‚‹æ–‡æ›¸ã‚„æƒ…å ±æºãŒã‚ã‚‹å ´åˆã¯å¿…ãšæ˜è¨˜ã—ã¦ãã ã•ã„**
3. **æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã‚„æ¨æ¸¬ã‚’å«ã‚€å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œè­°äº‹éŒ²ã‹ã‚‰ã¯æ˜ç¢ºã§ãªã„ãŒã€ä¸€èˆ¬çš„ã«ã¯â€¦ã€ã€Œæ–­ç‰‡çš„ãªæƒ…å ±ã‹ã‚‰æ¨æ¸¬ã™ã‚‹ã¨â€¦ã€ãªã©ï¼‰**
4. **å…·ä½“çš„ãªæƒ…å ±ï¼ˆæ—¥æ™‚ã€æ±ºå®šäº‹é …ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã€æ‹…å½“è€…ã€æœŸé™ãªã©ï¼‰ãŒã‚ã‚Œã°å¿…ãšè¨˜è¼‰ã—ã¦ãã ã•ã„**
5. **é–¢é€£ã™ã‚‹ä»–ã®è­°é¡Œã‚„æ–‡è„ˆãŒã‚ã‚Œã°ã€ç©æ¥µçš„ã«è¨€åŠã—ã¦ãã ã•ã„**
6. **æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„**

# å›ç­”ã®æ§‹é€ 
1. è³ªå•ã«å¯¾ã™ã‚‹ç›´æ¥çš„ãªå›ç­”ï¼ˆè€ƒå¯Ÿã‚„æ¨è«–ã‚’å«ã‚ã¦OKï¼‰
2. é–¢é€£ã™ã‚‹å…·ä½“çš„ãªæƒ…å ±ã‚„æ ¹æ‹ ï¼ˆæ–‡æ›¸åã‚„å‡ºå…¸ã€é–¢é€£åº¦é †ï¼‰
3. å¿…è¦ã«å¿œã˜ã¦ã€é–¢é€£ã™ã‚‹ä»–ã®è­°é¡Œã‚„ä¸€èˆ¬çš„ãªçŸ¥è¦‹ã¸ã®è¨€åŠ
4. ä¸æ˜ç‚¹ã‚„æ¨æ¸¬éƒ¨åˆ†ãŒã‚ã‚Œã°ã€ãã®æ—¨ã‚’æ˜è¨˜

è­°äº‹éŒ²ã®å†…å®¹ï¼ˆé–¢é€£åº¦é †ï¼‰ï¼š
{context}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ï¼š{query}

ä¸Šè¨˜ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€æ–­ç‰‡çš„ãªçŸ¥è­˜ã‚’çµ±åˆã—ã€è€ƒå¯Ÿã‚‚å«ã‚ã¦åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
"""

            user_prompt = system_prompt.format(
                context=context_text,
                query=query
            )
            
            # OpenAI APIã‚’å‘¼ã³å‡ºã—ï¼ˆmeeting_summarizer.pyã¨å®Œå…¨ã«åŒã˜æ–¹æ³•ï¼‰
            client = openai.OpenAI(api_key=OPENAI_API_KEY)
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯è­°äº‹éŒ²ã®å°‚é–€å®¶ã§ã™ã€‚è­°äº‹éŒ²ã®å†…å®¹ã®ã¿ã«åŸºã¥ã„ã¦ã€æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚å¤šãã®æ–‡æ›¸ã‚’å‚ç…§ã—ã¦åŒ…æ‹¬çš„ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,  # ã‚ˆã‚Šè©³ç´°ãªå›ç­”ã®ãŸã‚å¢—åŠ 
                temperature=0.2,   # ã‚ˆã‚Šä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã®ãŸã‚ä½ä¸‹
                top_p=0.9,        # å‰µé€ æ€§ã¨æ­£ç¢ºæ€§ã®ãƒãƒ©ãƒ³ã‚¹
                presence_penalty=0.1,  # ç¹°ã‚Šè¿”ã—ã‚’é¿ã‘ã‚‹
                frequency_penalty=0.1  # å¤šæ§˜æ€§ã‚’ä¿ã¤
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"AIå›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title="è­°äº‹éŒ²RAGã‚·ã‚¹ãƒ†ãƒ ",
        page_icon="ğŸ“‹",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ“‹ è­°äº‹éŒ²RAGã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ”§ è¨­å®š")
        
        # DBãƒ‘ã‚¹ã®è¨­å®š
        db_path = st.text_input(
            "ChromaDBãƒ‘ã‚¹",
            value="./chroma_db",
            help="ChromaDBã®ä¿å­˜ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        )
        
        # æ¤œç´¢çµæœæ•°ã®è¨­å®š
        n_results = st.slider(
            "æ¤œç´¢çµæœæ•°",
            min_value=1,
            max_value=100,  # æœ€å¤§å€¤ã‚’100ä»¶ã«å¢—åŠ 
            value=50,      # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’50ä»¶ã«å¤‰æ›´
            help="æ¤œç´¢ã§å–å¾—ã™ã‚‹çµæœæ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
        )
        
        # é¡ä¼¼åº¦é–¾å€¤ã®è¨­å®š
        similarity_threshold = st.slider(
            "é¡ä¼¼åº¦é–¾å€¤",
            min_value=0.0,
            max_value=1.0,
            value=0.3,     # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’30%ã«å¤‰æ›´
            step=0.05,     # ã‚ˆã‚Šç´°ã‹ã„èª¿æ•´ãŒã§ãã‚‹ã‚ˆã†ã«0.05åˆ»ã¿ã«å¤‰æ›´
            help="ã“ã®å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’æŒã¤æ¤œç´¢çµæœã®ã¿ã‚’RAGã«ä½¿ç”¨ã—ã¾ã™ï¼ˆæ¨å¥¨: 30%ä»¥ä¸Šï¼‰"
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®è¡¨ç¤º
        st.header("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        
        # OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªæƒ…å ±
        st.info(f"OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³: {openai_version}")
        
        # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        rag_system = MeetingRAGSystem(db_path)
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®è¡¨ç¤º
        if rag_system.collection:
            info = rag_system.get_collection_info()
            
            st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•°", info["total_count"])
           
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if not rag_system.collection:
        st.warning("ChromaDBã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚å…ˆã«è­°äº‹éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
        st.info("ä½¿ç”¨æ–¹æ³•:")
        st.code("python meeting_rag_processor.py transcription_20250823_153511.md")
        return
    
    st.header("ğŸ” æ¤œç´¢ãƒ»è³ªå•")
    
    # æ¤œç´¢ã‚¯ã‚¨ãƒªã®å…¥åŠ›
    search_query = st.text_input(
        "æ¤œç´¢ã‚¯ã‚¨ãƒªã¾ãŸã¯è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="ä¾‹: ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆã«ã¤ã„ã¦æ•™ãˆã¦",
        help="è­°äº‹éŒ²ã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã—ãŸã‚Šã€ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ãŸã‚Šã§ãã¾ã™"
    )
    
    # æ¤œç´¢ãƒœã‚¿ãƒ³ï¼ˆå¸¸ã«è¡¨ç¤ºã€å†…å®¹ãŒãªã„å ´åˆã¯ç„¡åŠ¹åŒ–ï¼‰
    search_button_disabled = not search_query or search_query.strip() == ""
    if st.button("ğŸ” æ¤œç´¢ãƒ»è³ªå•", type="primary", disabled=search_button_disabled):
        if search_button_disabled:
            st.warning("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            with st.spinner("æ¤œç´¢ä¸­..."):
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
                search_results = rag_system.search_documents(search_query, n_results, similarity_threshold)
    
    # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆ
    if not search_query or search_query.strip() == "":
        st.info("ğŸ’¡ ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è³ªå•ã‚„æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        st.success(f"âœ… æ¤œç´¢ã‚¯ã‚¨ãƒª: **{search_query}** ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸ")
    
    # æ¤œç´¢çµæœã®è¡¨ç¤º
    if search_query and not search_button_disabled:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
        search_results = rag_system.search_documents(search_query, n_results, similarity_threshold)
        
        if search_results:
            st.success(f"{len(search_results)}ä»¶ã®é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            
            # æ¤œç´¢çµæœãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰è‡ªå‹•çš„ã«AIå›ç­”ã‚’ç”Ÿæˆ
            st.markdown("---")
            st.markdown("## ğŸ¤– AIå›ç­”")
            
            # æ¤œç´¢çµæœã‚’é¡ä¼¼åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_results = [
                result for result in search_results 
                if result['similarity'] >= similarity_threshold
            ]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœã®è¡¨ç¤º
            if filtered_results:
                st.success(f"âœ… é¡ä¼¼åº¦é–¾å€¤({similarity_threshold:.1%})ã‚’æº€ãŸã™{len(filtered_results)}ä»¶ã®æ–‡æ›¸ã§RAGã‚’å®Ÿè¡Œã—ã¾ã™")
                
                # é™¤å¤–ã•ã‚ŒãŸçµæœã®æƒ…å ±
                excluded_count = len(search_results) - len(filtered_results)
                if excluded_count > 0:
                    st.info(f"âš ï¸ é¡ä¼¼åº¦ãŒä½ã„ãŸã‚{excluded_count}ä»¶ã®æ–‡æ›¸ã‚’é™¤å¤–ã—ã¾ã—ãŸ")
                
                # AIå›ç­”ã®ç”Ÿæˆ
                with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    ai_response = rag_system.generate_ai_response(search_query, filtered_results)
                    
                    # å›ç­”ã®è¡¨ç¤º
                    st.success("âœ… AIå›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                    
                    # å›ç­”ã‚’ç¾ã—ãè¡¨ç¤ºï¼ˆãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼‰
                    st.markdown("---")
                    st.markdown("### ğŸ’¬ AIã®å›ç­”")
                    
                    # å›ç­”ã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
                    st.markdown(f"""
                    <div style="
                        background-color: #f0f2f6;
                        padding: 20px;
                        border-radius: 10px;
                        border-left: 5px solid #1f77b4;
                        margin: 10px 0;
                        color: #333333;
                        font-size: 16px;
                        line-height: 1.6;
                    ">
                        {ai_response.replace(chr(10), '<br>')}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.markdown("---")
                    
                    # ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³ã¨è©³ç´°æƒ…å ±
                    col1, col2 = st.columns([1, 3])
                    
                    with col1:
                        if st.button("ğŸ“‹ å›ç­”ã‚’ã‚³ãƒ”ãƒ¼", key="copy_response"):
                            st.write("âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
                    
                    with col2:
                        st.info("ğŸ’¡ å›ç­”ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»–ã®å ´æ‰€ã§ä½¿ç”¨ã§ãã¾ã™")
                    
                    st.markdown("---")
                    
                    # å›ç­”ã®è©³ç´°æƒ…å ±
                    with st.expander("ğŸ” AIå›ç­”ã®è©³ç´°æƒ…å ±", expanded=False):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**â“ è³ªå•:**", search_query)
                            st.write("**ğŸ“š ä½¿ç”¨ã•ã‚ŒãŸæ–‡æ›¸æ•°:**", len(filtered_results))
                            st.write("**ğŸ” é¡ä¼¼åº¦é–¾å€¤:**", f"{similarity_threshold:.1%}")
                        
                        with col2:
                            st.write("**â° å›ç­”ç”Ÿæˆæ—¥æ™‚:**", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                            st.write("**ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:** GPT-4")
                        
                        # ä½¿ç”¨ã•ã‚ŒãŸæ–‡æ›¸ã®è¦ç´„
                        st.write("**ğŸ“– å‚è€ƒæ–‡æ›¸:**")
                        for i, result in enumerate(filtered_results):
                            similarity = result['similarity']
                            st.write(f"**ğŸ“„ æ–‡æ›¸{i+1}** (é–¢é€£åº¦: {similarity:.1%})")
                            st.write(f"- ğŸ·ï¸ ã‚¿ã‚¤ãƒ—: {result['metadata'].get('type', 'N/A')}")
                            st.write(f"- ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {result['metadata'].get('file_name', 'N/A')}")
                            if result['metadata'].get('subtitle'):
                                st.write(f"- ğŸ“ ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«: {result['metadata']['subtitle']}")
                            # â†“â†“â†“ ã“ã“ã‚’è¿½åŠ  â†“â†“â†“
                            with st.expander(f"ğŸ“„ æ–‡æ›¸{i+1} ã®å†…å®¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰", expanded=False):
                                st.write(result['content'])
                            st.write("---")                            
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±
                        st.write("**ğŸ”§ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±:**")
                        st.info("è­°äº‹éŒ²ã®å°‚é–€å®¶ã¨ã—ã¦ã€é¡ä¼¼åº¦é–¾å€¤ã‚’æº€ãŸã™é–¢é€£æ–‡æ›¸ã®å†…å®¹ã‚’åŸºã«ã€è³ªå•ã«æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¾ã—ãŸã€‚")
            else:
                st.warning(f"âš ï¸ é¡ä¼¼åº¦é–¾å€¤({similarity_threshold:.1%})ã‚’æº€ãŸã™æ–‡æ›¸ãŒã‚ã‚Šã¾ã›ã‚“")
                st.info("ä»¥ä¸‹ã®æ–¹æ³•ã‚’è©¦ã—ã¦ãã ã•ã„ï¼š")
                st.write("â€¢ é¡ä¼¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã‚‹")
                st.write("â€¢ æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã‚ˆã‚Šå…·ä½“çš„ã«ã™ã‚‹")
                st.write("â€¢ æ¤œç´¢çµæœæ•°ã‚’å¢—ã‚„ã™")
        else:
            st.warning("é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
        
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        "**è­°äº‹éŒ²RAGã‚·ã‚¹ãƒ†ãƒ ** | "
        "ChromaDB + OpenAI + Streamlit | "
        f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    )


if __name__ == "__main__":
    main()
